[
  {
    "objectID": "posts/doge/index.html",
    "href": "posts/doge/index.html",
    "title": "An LSTM Autoencoder for Dogecoin Anomaly Detection",
    "section": "",
    "text": "In this project, for my Deep Learning Class (DSAN 6660), I used neural networks to predict anomalous market behavior in the Dogecoin market, a popular cryptocurrency. More specifically, I use an LSTM autoencoder. There is no other existing literature that uses these methods relating specifically to Dogecoin. My final report can be found below.\n\n\nBelow is the presentation I gave to my class and professors at the end of the semester.\n\n\nAll code can be found at the GitHub link here: https://github.com/mattycars/DSAN_6600_Final_Project.git"
  },
  {
    "objectID": "posts/horse-racing/index.html",
    "href": "posts/horse-racing/index.html",
    "title": "Predicting Horse Racing Winners at the Hong Kong Jockey Club (HKJC)",
    "section": "",
    "text": "In this project, I predict horse racing winners and podium finishers at the Hong Kong Jockey Club. I use a variety of statistical methods including Naive Bayes, Random Forests, AdaBoost Models, and Gradient Boosting, specifically XGBoost. I was able to develop a model that, at the 1200m distance, under a specific set of race conditions, can predict horse racing finishers with around a 50% precision.\nThis project was completed as a part of DSAN 5000: Data Science and Analysis, an intro class in my first semester at Georgetown.\nThe link to project is hosted on a website found at this link."
  },
  {
    "objectID": "posts/nfl-homefield/index.html",
    "href": "posts/nfl-homefield/index.html",
    "title": "NFL Home & Away Performance Analysis",
    "section": "",
    "text": "In this project, I, along with a group, explore how NFL teams perform when they are the home team versus when they are the away team. We were able to quantify home field advantage by looking at a variety of NFL data including game-by-game data, win probabilities, and Elo ratings created by FiveThirtyEight. All code can be found here.\nBelow you will find the presentation we delivered to faculty on our analysis which provides a general overview of our project and its findings.\n\n\nAnd here is the more detailed final report we created."
  },
  {
    "objectID": "posts/lower-james/index.html",
    "href": "posts/lower-james/index.html",
    "title": "Water Quality in the Lower James Can Help Explain Phytoplankton Levels in the Chesapeake Bay",
    "section": "",
    "text": "This project explores data from the Lower James watershed, my hometown water shed, and how climate change has impacted it, along with the Chesapeake Bay downstream.\nI completed this project as a final project for a class during my first semester as a Georgetown student. The class was Data Science for a Changing Climate.\nAll code can be found here."
  },
  {
    "objectID": "posts/scholarship-climate/index.html",
    "href": "posts/scholarship-climate/index.html",
    "title": "Anthropogenic Climate Change and the Earth’s Changing Landscape",
    "section": "",
    "text": "I submitted this project as a part of an application for a scholarship available to returning Georgetown Data Science students. The prompt was to use data visualization to tell a story about climate data in Southeastern Utah they provided us. We were given a week to come up with a submission. I ended up winning the scholarship!\nThe project is hosted here."
  },
  {
    "objectID": "posts/avalanche-detection/index.html",
    "href": "posts/avalanche-detection/index.html",
    "title": "Using Deep Learning for Avalanche Detection with Ground-Based Photography",
    "section": "",
    "text": "In this project. I use raw image data and Convolutional Neural Networks (CNNs) to predict avalanches. I was able to develop a model with an accuracy of 77.7% in predicting avalanches and an accuracy of 80.6% for the TYPE of avalanche.\nThis project was completed as a part of a Computer Vision class I took at Georgetown.\nAll code for this project can be found here. Because the dataset was so large, I worked in Google Colab. I have yet to set up git for this project due to complications in having git set up in conjunction with Google Colab, so for now, it is resting on GoogleDrive."
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Project Portfolio",
    "section": "",
    "text": "An Exploration of Reddit Restaurant Data\n\n\n\n\n\n\n\nData Viz\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n  \n\n\n\n\nAn LSTM Autoencoder for Dogecoin Anomaly Detection\n\n\n\n\n\n\n\nDeep Learning\n\n\nTime Series\n\n\nFinance\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2024\n\n\n\n\n\n\n  \n\n\n\n\nHeat Exposure White Paper\n\n\n\n\n\n\n\nSustainability\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\n\n\n\n\n  \n\n\n\n\nUsing Deep Learning for Avalanche Detection with Ground-Based Photography\n\n\n\n\n\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n  \n\n\n\n\nAnthropogenic Climate Change and the Earth’s Changing Landscape\n\n\n\n\n\n\n\nData Viz\n\n\nSustainability\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\n\n\n\n\n  \n\n\n\n\nMarch Madness\n\n\n\n\n\n\n\nMachine Learning\n\n\nDeep Learning\n\n\nSports\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2024\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing Car Thefts in DC\n\n\n\n\n\n\n\nData Viz\n\n\nTime Series\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2024\n\n\n\n\n\n\n  \n\n\n\n\nDaily Stock Market Report ETL Pipeline\n\n\n\n\n\n\n\nData Viz\n\n\nTime Series\n\n\nFinance\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2024\n\n\n\n\n\n\n  \n\n\n\n\nPredicting Horse Racing Winners at the Hong Kong Jockey Club (HKJC)\n\n\n\n\n\n\n\nMachine Learning\n\n\nSports\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWater Quality in the Lower James Can Help Explain Phytoplankton Levels in the Chesapeake Bay\n\n\n\n\n\n\n\nData Viz\n\n\nSustainability\n\n\nTime Series\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\nNFL Home & Away Performance Analysis\n\n\n\n\n\n\n\nData Viz\n\n\nSports\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nWelcome to My Website.\n",
    "section": "",
    "text": "Welcome to My Website.\n\n\nA home for all of my thoughts. More content to come… For now, feel free to click here to learn more about me or here to see what kind of projects I have been working on."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! Matt here. Welcome to my website. I just graduated from the Data Science and Analytics graduate program at Georgetown University in December and am currently looking for a full-time work opportunity in the data science field. I graduated undergrad from the University of Virginia in 2022 with a degree in Statistics and Econometrics.\nMy interests exist in some sort of vast Euclidean space between AI/deep learning, economics, sports and sports handicapping, tech, and sustainability. I also am a marathoner, snowboarder, mountaineer, SCUBA diver, and beginner skydiver who is always up for an adventure. Enjoy your stay here and feel free to reach out about anything!"
  },
  {
    "objectID": "posts/car-theft/index.html",
    "href": "posts/car-theft/index.html",
    "title": "Visualizing Car Thefts in DC",
    "section": "",
    "text": "In this project, I worked with 3 other group members to visualize how car thefts in DC have increased over recent years. We took a look at where cars are being stolen in DC, what time of day they are being stolen, what types of cars are being stolen, and who is stealing the cars. We do all of these analyses through a “scrollytelling” to find WHY car thefts are increasing in DC.\nThe project can be at this link, hosted by one of of my peers that I worked on the project with."
  },
  {
    "objectID": "posts/stocks/index.html",
    "href": "posts/stocks/index.html",
    "title": "Daily Stock Market Report ETL Pipeline",
    "section": "",
    "text": "In this project, I worked with a couple partners to develop an Extract, Transform, and Load (ETL) pipeline that extracts stock market data from Polygon.io’s stock API and then creates a daily report before the market opens that day, highlighting market performance of the previous trading day. The pipeline runs automatically every morning with the help of a deployment on Prefect and sends us an email of the created stock report."
  },
  {
    "objectID": "posts/march-madness/index.html",
    "href": "posts/march-madness/index.html",
    "title": "March Madness",
    "section": "",
    "text": "In this project, 3 other group members and I developed a project that explores what goes into an upset in the NCAA Basektball Division I March Madness Tournament. We were able to develop a model that is able to predict upsets with a 78% accuracy. We explored various ML/DL techniques such as logistic regression, support vector machines (SVMs), and artificial neural networks (ANNs).\nBelow is the poster we presented to faculty in the Georgetown Data Science program.\n\n\nBelow is the full report we created for the project.\n\n\nAll code can be found here."
  },
  {
    "objectID": "posts/reddit/index.html",
    "href": "posts/reddit/index.html",
    "title": "An Exploration of Reddit Restaurant Data",
    "section": "",
    "text": "I completed this project with 3 other group members as a part of my Big Data and Cloud Computing Class (DSAN 6000). We used AWS and Azure to process over 1 terabyte of Reddit data in order to see if we could develop a restaraunt review mechanism using restaurant/food subreddits and natural language processing (NLP). The link to our final website can be found here.\nAll additional code can be found in this GitHub repo here."
  },
  {
    "objectID": "posts/heat-exposure/index.html",
    "href": "posts/heat-exposure/index.html",
    "title": "Heat Exposure White Paper",
    "section": "",
    "text": "I wrote this paper during my time as an intern at the Montgomery County Green Bank. It was a part of an effort of the Climate Resiliency team to start researching and brainstorming ways we can make communities, particuraly communities in and around Montgomery County, MD, more resilient to increased heat exposure incurred by climate change. The paper goes over some of the risks of heat exposure, who is most affected, and what we can do the increase their resiliency to the outlined dangers.\nMost of my work with the bank is sensitive and not for public consumption, but this paper is one of those projects that is okay to share. It showcases some of my writing and research abilities in addition to my passion for fighting climate change."
  }
]